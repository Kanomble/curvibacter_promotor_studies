{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f1cbad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir \"../data/\"\n",
    "gbfile=data_dir+'GCF_002163715.1_ASM216371v1_genomic.gbff'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca8d020e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio import SeqIO\n",
    "from Bio.Seq import Seq\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "from Bio.SeqFeature import SeqFeature, FeatureLocation\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d2a7714",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''parse_genbank_file_for_utr\n",
    "\n",
    "'''\n",
    "def parse_genbank_file_for_utr(gbfile:str,basepairs=200, end_basepairs=180,start_basepairs=60, filter_facing_seqs=True):\n",
    "\n",
    "    records = []\n",
    "    for record in SeqIO.parse(gbfile,'genbank'):\n",
    "        records.append(record)\n",
    "\n",
    "    print(\"[+] Working on {} genbank records\".format(len(records)))\n",
    "    print(\"[+] Extracting all sequences with location from end plus {}bp\".format(basepairs))\n",
    "    count = 0\n",
    "    feature_dict = {}\n",
    "    #list inherits all protein identifier from start to end of gb file\n",
    "    ordered_keys = []\n",
    "    for index, rec in enumerate(records):\n",
    "        try:\n",
    "            for feature in rec.features:\n",
    "                count += 1\n",
    "                try:\n",
    "                    if feature.type == 'gene':\n",
    "                        #if condition to get all sequences, even the ones without any new annotation\n",
    "                        if 'old_locus_tag' in feature.qualifiers:\n",
    "                            if feature.location.strand == -1:\n",
    "                                seq = records[0].seq[feature.location.end.position:feature.location.end.position+basepairs].reverse_complement()\n",
    "                                loc = (feature.location.end.position,feature.location.end.position+basepairs)\n",
    "\n",
    "                            elif feature.location.strand == 1:\n",
    "                                seq = records[0].seq[feature.location.start.position-basepairs:feature.location.start.position]\n",
    "                                loc = (feature.location.start.position-basepairs,feature.location.start.position)\n",
    "                            \n",
    "                            feature_dict[feature.qualifiers['old_locus_tag'][0]] = [feature.location,loc,seq,index]\n",
    "                            ordered_keys.append(feature.qualifiers['old_locus_tag'][0])\n",
    "\n",
    "\n",
    "                        else:\n",
    "                            if feature.location.strand == -1:\n",
    "                                seq = records[0].seq[feature.location.end.position:feature.location.end.position+basepairs].reverse_complement()\n",
    "                                loc = (feature.location.end.position,feature.location.end.position+basepairs)\n",
    "                            elif feature.location.strand == 1:\n",
    "                                seq = records[0].seq[feature.location.start.position-basepairs:feature.location.start.position]\n",
    "                                loc = (feature.location.start.position-basepairs,feature.location.start.position)\n",
    "                            \n",
    "                            feature_dict[feature.qualifiers['locus_tag'][0]] = [feature.location,loc,seq,index]\n",
    "                            ordered_keys.append(feature.qualifiers['locus_tag'][0])\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(\"[-] ERROR: {}\".format(e))\n",
    "                    pass\n",
    "        except Exception as e:\n",
    "            print(\"[-] ERROR: {}\".format(e))\n",
    "            continue\n",
    "    \n",
    "    #parsing feature dict - evaluating end location + basepairs of target sequences \n",
    "    target_promotor_seqs = {}\n",
    "    print(\"[+] Try Parsing Results For Putative Promotor Sequences\")\n",
    "    print(\"\\t[+] Applied filters: sequences have to be bigger than {} and smaller than {}\".format(end_basepairs,start_basepairs))\n",
    "    if filter_facing_seqs is True:\n",
    "        print(\"\\t[+] Filter out end facing sequences (-1 1 | 1 -1) that might share putative promotor sequences\")\n",
    "    for index, key in enumerate(ordered_keys):\n",
    "        #do not evaluate start and end sequences\n",
    "        if index > 0 and index < len(ordered_keys)-1:\n",
    "            cds = feature_dict[key]\n",
    "            \n",
    "            if cds[0].strand == -1:#if the strand is negative look at the next sequence \n",
    "                key_before = ordered_keys[index+1]\n",
    "                start = cds[0].end.position                \n",
    "                cds_before = feature_dict[key_before]\n",
    "                start_next_gene = cds_before[0].start.position\n",
    "        \n",
    "\n",
    "            elif cds[0].strand == 1:#if the strand is positive look at the sequence before\n",
    "                key_before = ordered_keys[index-1]\n",
    "                start = cds[0].start.position\n",
    "                cds_before = feature_dict[key_before]\n",
    "                start_next_gene = cds_before[0].end.position\n",
    "            \n",
    "            #filter out sequences that \"look on each other\"\n",
    "            if filter_facing_seqs is True:\n",
    "                if((cds[0].strand == -1 and cds_before[0].strand == 1) or (cds[0].strand == 1 and cds_before[0].strand == -1)) == False:\n",
    "                    if cds[0].strand == -1:\n",
    "                        if(abs(start_next_gene - start) <= end_basepairs) and (abs(start_next_gene - start) >= start_basepairs) :\n",
    "\n",
    "                            if (int(cds[0].end.position) < int(cds_before[0].start.position)):\n",
    "                                print(\"\\t[+] \",key, key_before, abs(start_next_gene - start), cds[0].strand, cds_before[0].strand)\n",
    "                                target_promotor_seqs[key] = [start_next_gene, start]\n",
    "                            else:\n",
    "                                print(\"\\t\\t[+] unusual overlapping sequences: {} - {} - strand: {}\".format(key,key_before, cds[0].strand))\n",
    "\n",
    "                    elif cds[0].strand == 1:\n",
    "                        if(abs(start_next_gene - start) <= end_basepairs) and (abs(start_next_gene - start) >= start_basepairs):\n",
    "                            if(int(cds_before[0].end.position) < int(cds[0].start.position)):\n",
    "                                print(\"\\t[+] \",key, key_before, abs(start_next_gene - start), cds[0].strand, cds_before[0].strand)\n",
    "                                target_promotor_seqs[key] = [start_next_gene, start]\n",
    "                            else:\n",
    "                                print(\"\\t\\t[+] unusual overlapping sequences: {} - {} - strand: {}\".format(key,key_before, cds[0].strand))\n",
    "\n",
    "\n",
    "            else:\n",
    "                if cds[0].strand == -1:\n",
    "                    if (abs(start_next_gene - start) <= end_basepairs) and (abs(start_next_gene - start) >= start_basepairs) :\n",
    "                        if(int(cds[0].end.position) < int(cds_before[0].start.position)) :\n",
    "                            print(\"\\t[+] \",key, key_before, abs(start_next_gene - start), cds[0].strand, cds_before[0].strand)\n",
    "                            target_promotor_seqs[key] = [start_next_gene, start]\n",
    "                        else:\n",
    "                            print(\"\\t\\t[+] unusual overlapping sequences: {} - {} - strand: {}\".format(key,key_before, cds[0].strand))                                       \n",
    "\n",
    "                elif cds[0].strand == 1:\n",
    "                    if(abs(start_next_gene - start) <= end_basepairs) and (abs(start_next_gene - start) >= start_basepairs):\n",
    "                        if (int(cds_before[0].end.position) < int(cds[0].start.position)):\n",
    "                            print(\"\\t[+] \",key, key_before, abs(start_next_gene - start), cds[0].strand, cds_before[0].strand)\n",
    "                            target_promotor_seqs[key] = [start_next_gene, start]\n",
    "                        else:\n",
    "                            print(\"\\t\\t[+] unusual overlapping sequences: {} - {} - strand: {}\".format(key,key_before, cds[0].strand))\n",
    "\n",
    "                            \n",
    "        targets = target_promotor_seqs.keys()\n",
    "        seqs = {}\n",
    "        for rec in records:\n",
    "            try:\n",
    "                for feature in rec.features:\n",
    "                    count += 1\n",
    "                    try:\n",
    "                        if feature.type == 'gene':\n",
    "                            if 'old_locus_tag' in feature.qualifiers:\n",
    "                                if feature.qualifiers['old_locus_tag'][0] in targets:\n",
    "                                    if feature.location.strand == -1:\n",
    "                                        seqs[feature.qualifiers['old_locus_tag'][0]] = rec.seq[feature.location.end.position:feature.location.end.position+basepairs]\n",
    "                                    else:\n",
    "                                        seqs[feature.qualifiers['old_locus_tag'][0]] = rec.seq[feature.location.start.position-basepairs:feature.location.start.position]\n",
    "\n",
    "                            else:\n",
    "                                if feature.qualifiers['locus_tag'][0] in targets:\n",
    "                                    if feature.location.strand == -1:\n",
    "                                        seqs[feature.qualifiers['locus_tag'][0]] = rec.seq[feature.location.end.position:feature.location.end.position+basepairs]\n",
    "                                    else:\n",
    "                                        seqs[feature.qualifiers['locus_tag'][0]] = rec.seq[feature.location.start.position-basepairs:feature.location.start.position]\n",
    "\n",
    "                                \n",
    "                    except Exception as e:\n",
    "                        print(\"[-] ERROR: {}\".format(e))\n",
    "                        pass\n",
    "            except Exception as e:\n",
    "                print(\"[-] ERROR: {}\".format(e))\n",
    "                continue        \n",
    "\n",
    "            \n",
    "    print(\"[+] DONE\")\n",
    "    return feature_dict, records, target_promotor_seqs, ordered_keys, seqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91ec69f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''extract_sequences_based_on_target_promotor_seqs_dict\n",
    "\n",
    "'''\n",
    "def extract_sequences_based_on_target_promotor_seqs_dict(feature_dict:dict,target_promotor_seqs:dict, records:list)->dict:\n",
    "    seqs = {}\n",
    "    \n",
    "    print(\"[+] Trying to extract putative promotor sequences\")\n",
    "    for target in target_promotor_seqs.keys():\n",
    "        if feature_dict[target][0].strand == 1:\n",
    "            loc_cds_start = target_promotor_seqs[target][0]\n",
    "            loc_cds_end = target_promotor_seqs[target][1]\n",
    "            try:\n",
    "                seqs[target] = records[feature_dict[target][3]].seq[loc_cds_start:loc_cds_end].__str__()\n",
    "            except Exception as e:\n",
    "                print(\"[-] ERROR: {}\".format(e))\n",
    "        if feature_dict[target][0].strand == -1:\n",
    "            loc_cds_start = target_promotor_seqs[target][1]\n",
    "            loc_cds_end = target_promotor_seqs[target][0]\n",
    "            try:\n",
    "                seqs[target] = records[feature_dict[target][3]].seq[loc_cds_start:loc_cds_end].reverse_complement().__str__()\n",
    "            except Exception as e:\n",
    "                print(\"[-] ERROR: {}\".format(e))\n",
    "    print(\"[+] DONE\")\n",
    "    return seqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7060025",
   "metadata": {},
   "outputs": [],
   "source": [
    "#19.09.2022 downloaded from NCBI refseq ftp fileserver\n",
    "res = parse_genbank_file_for_utr(gbfile, end_basepairs=170, start_basepairs=60)\n",
    "seqs = extract_sequences_based_on_target_promotor_seqs_dict(res[0],res[2], res[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22adef6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"[+] Number of target promotor sequences: {}\".format(len(res[2])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e22a5f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"[+] Number of extracted sequences: {}\".format(len(seqs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6357ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_seqs=pd.DataFrame(seqs,index=['seq']).transpose()\n",
    "df_seqs = df_seqs.reset_index()\n",
    "df_seqs.columns=['aep','seq']\n",
    "df_seqs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29514e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "deseq2_excel=data_dir + \"excel_sheet_ordered_degs_curvibacter_aep_to_wp.xlsx\"\n",
    "deseq2_df=pd.read_excel(deseq2_excel)\n",
    "deseq2_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07737bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "promotor_stength_df=deseq2_df.merge(df_seqs,on='aep')\n",
    "f = lambda s: s.replace(\",\",\".\")\n",
    "promotor_stength_df['Wp_Number'] = promotor_stength_df['Wp_Number'].apply(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b7b639",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"[+] Number of target promotors after merging with transcriptome dataframe: {}\".format(len(promotor_stength_df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72000294",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"[*] Extracting sequences that do not reside in the merged dataframe ...\")\n",
    "print(\"\\t[*] Those sequences are mainly composed of tRNAs or other small nucleotide sequences\")\n",
    "diff = [d for d in list(df_seqs.aep.values) if d not in list(promotor_stength_df.aep)] # list of sequences that have putative promotor utrs but do not reside in the transcriptome dataframe\n",
    "print(\"\\t[*] DONE\")\n",
    "#e.g. AEP_00144 is a tRNA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6737d413",
   "metadata": {},
   "outputs": [],
   "source": [
    "diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff3bb98",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_reads_path=data_dir + \"raw_read_counts.csv\"\n",
    "raw_reads_df=pd.read_csv(raw_reads_path)\n",
    "raw_reads_df.columns=[\"Wp_Number\",\"G1\",\"G2\",\"G3\",\"Hydra1\",\"Hydra2\",\"Hydra3\"]\n",
    "raw_reads_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "388c85b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "promotor_stength_raw_df=promotor_stength_df.merge(raw_reads_df,on=\"Wp_Number\")\n",
    "promotor_stength_raw_df['readCountMeanGSamples'] = promotor_stength_raw_df[['G1','G2','G3']].mean(axis=1)\n",
    "promotor_stength_raw_df['readCountMeanNormalized'] = promotor_stength_raw_df['readCountMeanGSamples']/promotor_stength_raw_df['readCountMeanGSamples'].max()\n",
    "promotor_stength_raw_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c71dd77b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"[+] Length of dataframe after merging raw read data: {}\".format(len(promotor_stength_raw_df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc21dc93",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_targets = promotor_stength_raw_df[['Wp_Number','aep','readCountMeanGSamples','readCountMeanNormalized','log2FoldChange','seq']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "487dd941",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_targets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dac681fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#top 400 expressed regions\n",
    "high_400 = df_targets.sort_values(by='readCountMeanNormalized', ascending=False)[:400]\n",
    "#smallest 100 of the remaining regions\n",
    "other_seqs = df_targets.sort_values(by='readCountMeanNormalized', ascending=False)[400:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bfbf899",
   "metadata": {},
   "outputs": [],
   "source": [
    "high_400.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e8daa27",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating sequence length column for the subset of the smallest 100 of remaining regions\n",
    "seq_length=lambda seq: len(seq)\n",
    "other_seqs['seq_length']=other_seqs['seq'].apply(seq_length)\n",
    "high_400['seq_length']=high_400['seq'].apply(seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dbcc4af",
   "metadata": {},
   "outputs": [],
   "source": [
    "low_100=other_seqs.sort_values(by='seq_length',ascending=True)[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bcbd7cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df=pd.concat([high_400,low_100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff12fcc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#values for plotting\n",
    "ordered_gene_list = res[3] #ordered_dict\n",
    "result_gene_list = list(result_df['aep'])\n",
    "steps = 1/len(ordered_gene_list)\n",
    "\n",
    "x_values=np.arange(1,len(ordered_gene_list)+1)*steps\n",
    "y_values=np.repeat(1,len(x_values))\n",
    "#print(len(x_values) == len(y_values))\n",
    "x2_values=[]\n",
    "for key,value in zip(ordered_gene_list,x_values):\n",
    "    if key in result_gene_list:\n",
    "        x2_values.append(value)\n",
    "y2_values=list(np.repeat(1,len(x2_values)))\n",
    "#print(len(x2_values) == 500)\n",
    "#print(len(x2_values) == len(y2_values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "842a1675",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(30,8))\n",
    "plt.scatter(x=x_values,y=y_values, s=1000)\n",
    "plt.scatter(x=x2_values,y=y2_values, s=5, c='r')\n",
    "plt.ylim(0.9,1.1)\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7d66ddc",
   "metadata": {},
   "source": [
    "# Trimming Length Of Sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f6d1484",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the list of promoter sequences in 5' to 3' direction in a list\n",
    "raw_library = []\n",
    "\n",
    "# determine maximum length of promoter site to be used for expression and the maximum size of oligos to order\n",
    "promoter_max_len = 98\n",
    "synthesis_maxlen = 150\n",
    "# determine sequences for cloning to be attached to the promoters\n",
    "upstream_cloningsite = \"tcgagtacgacttcggtctcaGGAGc\"\n",
    "downstream_cloningsite = \"cAATGtgagaccgaacgtcagtgatc\"\n",
    "# random sequence to fill synthesis order, will be cut during cloning and has no impact on construct\n",
    "fillup = \"ATCGATCGCTAGCTAGCTAGCATCGACTATCGTCGATCGATCGATGCATGCATCTGTACGATCGACTAGCTAGTCGACTATCGACTGACTGACTGACTG\"\n",
    "finalorder = []\n",
    "for i in range(len(raw_library)):\n",
    "    finalorder.append(i)\n",
    "\n",
    "\n",
    "for i in raw_library:\n",
    "    #save the original sequence to get raw_library.index in the end\n",
    "    rawstring = i\n",
    "    # cut off first base to match final RBS distance in construct\n",
    "    i = i[:-1]\n",
    "    # trimming too long promoters\n",
    "    if len(i) > promoter_max_len:\n",
    "        overlength = len(i) - promoter_max_len\n",
    "        i = i[overlength:]\n",
    "        # adding cloning sites to both ends\n",
    "    i = upstream_cloningsite + i\n",
    "    i += downstream_cloningsite\n",
    "    #fill up synthesis for order of equal length oligos\n",
    "    i = fillup + i\n",
    "    overlength_syn = len(i) - synthesis_maxlen\n",
    "    i = i[overlength_syn:]\n",
    "    #put new strings into final order list\n",
    "    finalorder[raw_library.index(rawstring)] = i\n",
    "\n",
    "\n",
    "# checks if size of the list, size of each oligo is correct\n",
    "for i in finalorder:\n",
    "    if len(i) == synthesis_maxlen:\n",
    "        print(i)\n",
    "        print(\"length:\" + str(len(i)))\n",
    "    else:\n",
    "        print(\"ERROR: oligo has not the correct length\")\n",
    "if len(finalorder) == len(raw_library):\n",
    "    print(\"size of order is equal to library:\" + str(len(finalorder)))\n",
    "else:\n",
    "    print(\"ERROR: size of order doesnt match original library\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bb3abc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the list of promoter sequences in 5' to 3' direction in a list\n",
    "raw_library = list(result_df['seq'])\n",
    "\n",
    "# determine maximum length of promoter site to be used for expression and the maximum size of oligos to order\n",
    "promoter_max_len = 98\n",
    "synthesis_maxlen = 150\n",
    "# determine sequences for cloning to be attached to the promoters\n",
    "# designed in snapgene by maurice mager\n",
    "upstream_cloningsite = \"tcgagtacgacttcggtctcaGGAGc\"\n",
    "downstream_cloningsite = \"cAATGtgagaccgaacgtcagtgatc\"\n",
    "\n",
    "# random sequence to fill synthesis order, will be cut during cloning and has no impact on construct\n",
    "# filling of random nucleotides behind cloning sites if sequence too small e.g. < 98\n",
    "fillup = \"ATCGATCGCTAGCTAGCTAGCATCGACTATCGTCGATCGATCGATGCATGCATCTGTACGATCGACTAGCTAGTCGACTATCGACTGACTGACTGACTG\"\n",
    "\n",
    "aep_seq={}\n",
    "for aep,seq in zip(result_df['aep'],result_df['seq']):\n",
    "    #save the original sequence to get raw_library.index in the end\n",
    "    rawstring = seq\n",
    "    # cut off first base to match final RBS distance in construct - why?\n",
    "    seq = seq[:-1]\n",
    "    # trimming too long promoters\n",
    "    if len(seq) > promoter_max_len:\n",
    "        print(\"[+] Trimming sequence: {} with length: {}\".format(aep,len(seq)))\n",
    "        overlength = len(seq) - promoter_max_len\n",
    "        seq = seq[overlength:]\n",
    "        \n",
    "    # adding cloning sites to both ends\n",
    "    seq = upstream_cloningsite + seq\n",
    "    seq += downstream_cloningsite\n",
    "    \n",
    "    #fill up synthesis for order of equal length oligos\n",
    "    seq = fillup + seq\n",
    "    overlength_syn = len(seq) - synthesis_maxlen\n",
    "    seq = seq[overlength_syn:]\n",
    "\n",
    "    aep_seq[aep]=seq\n",
    "\n",
    "\n",
    "# checks if size of the list, size of each oligo is correct\n",
    "for aep in aep_seq.keys():\n",
    "    if len(aep_seq[aep]) == synthesis_maxlen:\n",
    "        print(\"[+] {}\".format(aep))\n",
    "        print(\"\\t[+] length:\" + str(len(aep_seq[aep])))\n",
    "    else:\n",
    "        print(\"[-] ERROR: oligo for {} has not the correct length\".format(aep))\n",
    "if len(aep_seq.keys()) == len(raw_library):\n",
    "    print(\"[+] size of order is equal to library\")\n",
    "else:\n",
    "    print(\"[-] ERROR: size of order doesnt match original library\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f433cce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "trimmed_seqs_df=pd.DataFrame(aep_seq, index=['seq']).transpose()\n",
    "trimmed_seqs_df = trimmed_seqs_df.reset_index()\n",
    "trimmed_seqs_df.columns=['aep','trimmed_seq']\n",
    "trimmed_seqs_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fafdc61",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df=result_df.merge(trimmed_seqs_df,on='aep')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bc2ce67",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6adbbed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# restriction size filtering:\n",
    "bbs1=\"GAAGAC\"\n",
    "bsmb1=\"CGTCTC\"\n",
    "bsa1=\"GGTCTC\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9efb079",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered=[]\n",
    "for aep,seq in zip(result_df['aep'],result_df['seq']):\n",
    "    if bsa1 in str(seq):\n",
    "        filtered.append(aep)\n",
    "        print(\"[+] Found BSA1 Restriction site: {} in {}\".format(bsa1,aep))\n",
    "        idx=result_df[result_df['aep'] == aep].index.to_list()\n",
    "        if len(idx) > 1:\n",
    "            raise Exception(\"[-] Multiple rows for one target\")\n",
    "        else:\n",
    "            idx=idx[0]\n",
    "            print(\"[+] Removing row {} from dataframe\".format(idx))\n",
    "            result_df=result_df.drop(idx)\n",
    "    if bbs1 in str(seq):\n",
    "        print(\"\\t[+] Found BBS1 Restriction site: {} in {}\".format(bbs1,aep))\n",
    "    if bsmb1 in str(seq):\n",
    "        print(\"\\t[+] Found BSMB1 Restriction site: {} in {}\".format(bsmb1,aep))\n",
    "print(\"[-] Number of promotors with restriction sites: {}\".format(len(filtered)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4166ea17",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir_excel=data_dir + \"target_promotors.xlsx\"\n",
    "result_df.to_excel(data_dir_excel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa6465ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "additional_promotor_seqs=[\"AEP_03486\",\"AEP_03466\",\"AEP_03465\",\"AEP_03459\",\"AEP_02900\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
