{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "14de9ddd",
   "metadata": {},
   "source": [
    "# Parsing GenBank File For Promoter Sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f1cbad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting up imports and data directories\n",
    "data_dir=\"../data/\"\n",
    "gbfile=data_dir+'GCF_002163715.1_ASM216371v1_genomic.gbff'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca8d020e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio import SeqIO\n",
    "from Bio.Seq import Seq\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "from Bio.SeqFeature import SeqFeature, FeatureLocation\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d2a7714",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''parse_genbank_file_for_utr\n",
    "\n",
    "    This function parses a given GenBank file and extracts all UTR regions that do not face each other.\n",
    "    It creates a comprehensive output: feature_dict, records, target_promotor_seqs, ordered_keys, seqs\n",
    "    The feature_dict is a dictionary of all features in the GenBank file labelled as gene, it saves the position\n",
    "    and the strand as well as the sequence itself. Records inherits the GenBank records within the GenBank file.\n",
    "    Target_promoter_seqs inherits the sequences with UTRs and their corresponding positions on the genome.\n",
    "    Ordered_keys is a list of keys for the feature_dict dictionary that is ordered (meaning this list preserves the\n",
    "    occurence of sequences within the genome of the GenBank file) and seqs is a dictionary with sequences of the UTRs\n",
    "    in the direction on which they occure within the DNA sequence of the GenBank file.\n",
    "    \n",
    "    :param gbfile\n",
    "        :type str\n",
    "    :param basepairs\n",
    "        :type int\n",
    "    :param end_basepairs\n",
    "        :type int\n",
    "    :param start_basepairs\n",
    "        :type int\n",
    "    :param filter_facing_seqs\n",
    "        :type bool\n",
    "    \n",
    "    :returns feature_dict, records, target_promotor_seqs, ordered_keys, seqs\n",
    "        :type tuple(dict, list, dict, list, dict)\n",
    "\n",
    "'''\n",
    "def parse_genbank_file_for_utr(gbfile:str,\n",
    "                               basepairs=200, \n",
    "                               end_basepairs=180,\n",
    "                               start_basepairs=60, \n",
    "                               filter_facing_seqs=True)->tuple:\n",
    "\n",
    "    records = []\n",
    "    for record in SeqIO.parse(gbfile,'genbank'):\n",
    "        records.append(record)\n",
    "\n",
    "    print(\"[+] Working on {} genbank records\".format(len(records)))\n",
    "    print(\"[+] Extracting all sequences with location from end plus {}bp\".format(basepairs))\n",
    "    count = 0\n",
    "    feature_dict = {}\n",
    "    #list inherits all protein identifier from start to end of gb file\n",
    "    ordered_keys = []\n",
    "    for index, rec in enumerate(records):\n",
    "        try:\n",
    "            for feature in rec.features:\n",
    "                count += 1\n",
    "                try:\n",
    "                    if feature.type == 'gene':\n",
    "                        #if condition to get all sequences, even the ones without any new annotation\n",
    "                        if 'old_locus_tag' in feature.qualifiers:\n",
    "                            if feature.location.strand == -1:\n",
    "                                seq = records[0].seq[feature.location.end.position:feature.location.end.position+basepairs].reverse_complement()\n",
    "                                loc = (feature.location.end.position,feature.location.end.position+basepairs)\n",
    "\n",
    "                            elif feature.location.strand == 1:\n",
    "                                seq = records[0].seq[feature.location.start.position-basepairs:feature.location.start.position]\n",
    "                                loc = (feature.location.start.position-basepairs,feature.location.start.position)\n",
    "                            \n",
    "                            feature_dict[feature.qualifiers['old_locus_tag'][0]] = [feature.location,loc,seq,index]\n",
    "                            ordered_keys.append(feature.qualifiers['old_locus_tag'][0])\n",
    "\n",
    "\n",
    "                        else:\n",
    "                            if feature.location.strand == -1:\n",
    "                                seq = records[0].seq[feature.location.end.position:feature.location.end.position+basepairs].reverse_complement()\n",
    "                                loc = (feature.location.end.position,feature.location.end.position+basepairs)\n",
    "                            elif feature.location.strand == 1:\n",
    "                                seq = records[0].seq[feature.location.start.position-basepairs:feature.location.start.position]\n",
    "                                loc = (feature.location.start.position-basepairs,feature.location.start.position)\n",
    "                            \n",
    "                            feature_dict[feature.qualifiers['locus_tag'][0]] = [feature.location,loc,seq,index]\n",
    "                            ordered_keys.append(feature.qualifiers['locus_tag'][0])\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(\"[-] ERROR: {}\".format(e))\n",
    "                    pass\n",
    "        except Exception as e:\n",
    "            print(\"[-] ERROR: {}\".format(e))\n",
    "            continue\n",
    "    \n",
    "    #parsing feature dict - evaluating end location + basepairs of target sequences \n",
    "    target_promotor_seqs = {}\n",
    "    print(\"[+] Try Parsing Results For Putative Promotor Sequences\")\n",
    "    print(\"\\t[+] Applied filters: sequences have to be smaller than {} and bigger than {}\".format(end_basepairs,start_basepairs))\n",
    "    if filter_facing_seqs is True:\n",
    "        print(\"\\t[+] Filter out end facing sequences (-1 1 | 1 -1) that might share putative promotor sequences\")\n",
    "    for index, key in enumerate(ordered_keys):\n",
    "        #do not evaluate start and end sequences\n",
    "        if index > 0 and index < len(ordered_keys)-1:\n",
    "            cds = feature_dict[key]\n",
    "            \n",
    "            if cds[0].strand == -1:#if the strand is negative look at the next sequence \n",
    "                key_before = ordered_keys[index+1]\n",
    "                start = cds[0].end.position                \n",
    "                cds_before = feature_dict[key_before]\n",
    "                start_next_gene = cds_before[0].start.position\n",
    "        \n",
    "\n",
    "            elif cds[0].strand == 1:#if the strand is positive look at the sequence before\n",
    "                key_before = ordered_keys[index-1]\n",
    "                start = cds[0].start.position\n",
    "                cds_before = feature_dict[key_before]\n",
    "                start_next_gene = cds_before[0].end.position\n",
    "            \n",
    "            #filter out sequences that \"look on each other\"\n",
    "            if filter_facing_seqs is True:\n",
    "                if((cds[0].strand == -1 and cds_before[0].strand == 1) or (cds[0].strand == 1 and cds_before[0].strand == -1)) == False:\n",
    "                    if cds[0].strand == -1:\n",
    "                        if(abs(start_next_gene - start) <= end_basepairs) and (abs(start_next_gene - start) >= start_basepairs) :\n",
    "\n",
    "                            if (int(cds[0].end.position) < int(cds_before[0].start.position)):\n",
    "                                print(\"\\t[+] \",key, key_before, abs(start_next_gene - start), cds[0].strand, cds_before[0].strand)\n",
    "                                target_promotor_seqs[key] = [start_next_gene, start]\n",
    "                            else:\n",
    "                                print(\"\\t\\t[+] unusual overlapping sequences: {} - {} - strand: {}\".format(key,key_before, cds[0].strand))\n",
    "\n",
    "                    elif cds[0].strand == 1:\n",
    "                        if(abs(start_next_gene - start) <= end_basepairs) and (abs(start_next_gene - start) >= start_basepairs):\n",
    "                            if(int(cds_before[0].end.position) < int(cds[0].start.position)):\n",
    "                                print(\"\\t[+] \",key, key_before, abs(start_next_gene - start), cds[0].strand, cds_before[0].strand)\n",
    "                                target_promotor_seqs[key] = [start_next_gene, start]\n",
    "                            else:\n",
    "                                print(\"\\t\\t[+] unusual overlapping sequences: {} - {} - strand: {}\".format(key,key_before, cds[0].strand))\n",
    "\n",
    "\n",
    "            else:\n",
    "                if cds[0].strand == -1:\n",
    "                    if (abs(start_next_gene - start) <= end_basepairs) and (abs(start_next_gene - start) >= start_basepairs) :\n",
    "                        if(int(cds[0].end.position) < int(cds_before[0].start.position)) :\n",
    "                            print(\"\\t[+] \",key, key_before, abs(start_next_gene - start), cds[0].strand, cds_before[0].strand)\n",
    "                            target_promotor_seqs[key] = [start_next_gene, start]\n",
    "                        else:\n",
    "                            print(\"\\t\\t[+] unusual overlapping sequences: {} - {} - strand: {}\".format(key,key_before, cds[0].strand))                                       \n",
    "\n",
    "                elif cds[0].strand == 1:\n",
    "                    if(abs(start_next_gene - start) <= end_basepairs) and (abs(start_next_gene - start) >= start_basepairs):\n",
    "                        if (int(cds_before[0].end.position) < int(cds[0].start.position)):\n",
    "                            print(\"\\t[+] \",key, key_before, abs(start_next_gene - start), cds[0].strand, cds_before[0].strand)\n",
    "                            target_promotor_seqs[key] = [start_next_gene, start]\n",
    "                        else:\n",
    "                            print(\"\\t\\t[+] unusual overlapping sequences: {} - {} - strand: {}\".format(key,key_before, cds[0].strand))\n",
    "\n",
    "                            \n",
    "        targets = target_promotor_seqs.keys()\n",
    "        seqs = {}\n",
    "        for rec in records:\n",
    "            try:\n",
    "                for feature in rec.features:\n",
    "                    count += 1\n",
    "                    try:\n",
    "                        if feature.type == 'gene':\n",
    "                            if 'old_locus_tag' in feature.qualifiers:\n",
    "                                if feature.qualifiers['old_locus_tag'][0] in targets:\n",
    "                                    if feature.location.strand == -1:\n",
    "                                        seqs[feature.qualifiers['old_locus_tag'][0]] = rec.seq[feature.location.end.position:feature.location.end.position+basepairs]\n",
    "                                    else:\n",
    "                                        seqs[feature.qualifiers['old_locus_tag'][0]] = rec.seq[feature.location.start.position-basepairs:feature.location.start.position]\n",
    "\n",
    "                            else:\n",
    "                                if feature.qualifiers['locus_tag'][0] in targets:\n",
    "                                    if feature.location.strand == -1:\n",
    "                                        seqs[feature.qualifiers['locus_tag'][0]] = rec.seq[feature.location.end.position:feature.location.end.position+basepairs]\n",
    "                                    else:\n",
    "                                        seqs[feature.qualifiers['locus_tag'][0]] = rec.seq[feature.location.start.position-basepairs:feature.location.start.position]\n",
    "\n",
    "                                \n",
    "                    except Exception as e:\n",
    "                        print(\"[-] ERROR: {}\".format(e))\n",
    "                        pass\n",
    "            except Exception as e:\n",
    "                print(\"[-] ERROR: {}\".format(e))\n",
    "                continue        \n",
    "\n",
    "            \n",
    "    print(\"[+] DONE\")\n",
    "    return feature_dict, records, target_promotor_seqs, ordered_keys, seqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91ec69f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''extract_sequences_based_on_target_promotor_seqs_dict\n",
    "\n",
    "    Helper function to extract the target sequences from the GenBank files.\n",
    "    This function parses the results of parse_genbank_file_for_utr and returns \n",
    "    the true UTR sequences.\n",
    "    \n",
    "    :param feature_dict\n",
    "        :type dict\n",
    "    :param target_promoter_seqs\n",
    "        :type dict\n",
    "    :param records\n",
    "        :type list\n",
    "    \n",
    "    :returns seqs\n",
    "        :type dict\n",
    "\n",
    "'''\n",
    "def extract_sequences_based_on_target_promotor_seqs_dict(feature_dict:dict,\n",
    "                                                         target_promotor_seqs:dict, \n",
    "                                                         records:list)->dict:\n",
    "    seqs = {}\n",
    "    \n",
    "    print(\"[+] Trying to extract putative promotor sequences\")\n",
    "    for target in target_promotor_seqs.keys():\n",
    "        if feature_dict[target][0].strand == 1:\n",
    "            loc_cds_start = target_promotor_seqs[target][0]\n",
    "            loc_cds_end = target_promotor_seqs[target][1]\n",
    "            try:\n",
    "                seqs[target] = records[feature_dict[target][3]].seq[loc_cds_start:loc_cds_end].__str__()\n",
    "            except Exception as e:\n",
    "                print(\"[-] ERROR: {}\".format(e))\n",
    "        if feature_dict[target][0].strand == -1:\n",
    "            loc_cds_start = target_promotor_seqs[target][1]\n",
    "            loc_cds_end = target_promotor_seqs[target][0]\n",
    "            try:\n",
    "                seqs[target] = records[feature_dict[target][3]].seq[loc_cds_start:loc_cds_end].reverse_complement().__str__()\n",
    "            except Exception as e:\n",
    "                print(\"[-] ERROR: {}\".format(e))\n",
    "    print(\"[+] DONE\")\n",
    "    return seqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7060025",
   "metadata": {},
   "outputs": [],
   "source": [
    "#19.09.2022 downloaded from NCBI refseq ftp fileserver\n",
    "res = parse_genbank_file_for_utr(gbfile, end_basepairs=170, start_basepairs=60)\n",
    "seqs = extract_sequences_based_on_target_promotor_seqs_dict(res[0],res[2], res[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22adef6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"[+] Number of target promotor sequences: {}\".format(len(res[2])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e22a5f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"[+] Number of extracted sequences: {}\".format(len(seqs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6357ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_seqs=pd.DataFrame(seqs,index=['seq']).transpose()\n",
    "df_seqs = df_seqs.reset_index()\n",
    "df_seqs.columns=['aep','seq']\n",
    "df_seqs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29514e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "deseq2_excel=data_dir + \"excel_sheet_ordered_degs_curvibacter_aep_to_wp.xlsx\"\n",
    "deseq2_df=pd.read_excel(deseq2_excel)\n",
    "deseq2_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07737bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "promotor_stength_df=deseq2_df.merge(df_seqs,on='aep')\n",
    "f = lambda s: s.replace(\",\",\".\")\n",
    "promotor_stength_df['Wp_Number'] = promotor_stength_df['Wp_Number'].apply(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b7b639",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"[+] Number of target promoters after merging with transcriptome dataframe: {}\".format(len(promotor_stength_df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72000294",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"[*] Extracting sequences that do not reside in the merged dataframe ...\")\n",
    "print(\"\\t[*] Those sequences are mainly composed of tRNAs or other small nucleotide sequences\")\n",
    "diff = [d for d in list(df_seqs.aep.values) if d not in list(promotor_stength_df.aep)] # list of sequences that have putative promotor utrs but do not reside in the transcriptome dataframe\n",
    "print(\"\\t[*] DONE\")\n",
    "#e.g. AEP_00144 is a tRNA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff3bb98",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_reads_path=data_dir + \"raw_read_counts.csv\"\n",
    "raw_reads_df=pd.read_csv(raw_reads_path)\n",
    "raw_reads_df.columns=[\"Wp_Number\",\"G1\",\"G2\",\"G3\",\"Hydra1\",\"Hydra2\",\"Hydra3\"]\n",
    "raw_reads_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "388c85b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "promotor_stength_raw_df=promotor_stength_df.merge(raw_reads_df,on=\"Wp_Number\")\n",
    "promotor_stength_raw_df['readCountMeanGSamples'] = promotor_stength_raw_df[['G1','G2','G3']].mean(axis=1)\n",
    "promotor_stength_raw_df['readCountMeanNormalized'] = promotor_stength_raw_df['readCountMeanGSamples']/promotor_stength_raw_df['readCountMeanGSamples'].max()\n",
    "promotor_stength_raw_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c71dd77b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"[+] Length of dataframe after merging raw read data: {}\".format(len(promotor_stength_raw_df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc21dc93",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_targets = promotor_stength_raw_df[['Wp_Number','aep','readCountMeanGSamples','readCountMeanNormalized','log2FoldChange','seq']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "487dd941",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_targets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abeaf6b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_targets.to_csv(\"../results/readCountsNormalizedWpToAEP.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c9206de",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df=df_targets.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ec47286",
   "metadata": {},
   "source": [
    "# Filtering for high/low expressed genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dac681fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#top 400 expressed regions\n",
    "high_400 = df_targets.sort_values(by='readCountMeanNormalized', ascending=False)[:400]\n",
    "#smallest 100 of the remaining regions\n",
    "other_seqs = df_targets.sort_values(by='readCountMeanNormalized', ascending=False)[400:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bfbf899",
   "metadata": {},
   "outputs": [],
   "source": [
    "high_400.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e8daa27",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating sequence length column for the subset of the smallest 100 of remaining regions\n",
    "seq_length=lambda seq: len(seq)\n",
    "other_seqs['seq_length']=other_seqs['seq'].apply(seq_length)\n",
    "high_400['seq_length']=high_400['seq'].apply(seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dbcc4af",
   "metadata": {},
   "outputs": [],
   "source": [
    "low_100=other_seqs.sort_values(by='seq_length',ascending=True)[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bcbd7cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "read_level_result_df=pd.concat([high_400,low_100])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08d0508d",
   "metadata": {},
   "source": [
    "## Plotting genome location of target sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff12fcc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#values for plotting\n",
    "ordered_gene_list = res[3] #ordered_dict\n",
    "result_gene_list = list(result_df['aep'])\n",
    "steps = 1/len(ordered_gene_list)\n",
    "\n",
    "x_values=np.arange(1,len(ordered_gene_list)+1)*steps\n",
    "y_values=np.repeat(1,len(x_values))\n",
    "#print(len(x_values) == len(y_values))\n",
    "x2_values=[]\n",
    "for key,value in zip(ordered_gene_list,x_values):\n",
    "    if key in result_gene_list:\n",
    "        x2_values.append(value)\n",
    "y2_values=list(np.repeat(1,len(x2_values)))\n",
    "#print(len(x2_values) == 500)\n",
    "#print(len(x2_values) == len(y2_values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "842a1675",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(30,8))\n",
    "plt.scatter(x=x_values,y=y_values, s=1000)\n",
    "plt.scatter(x=x2_values,y=y2_values, s=5, c='r')\n",
    "plt.ylim(0.9,1.1)\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96154c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_promoters = []\n",
    "with open(\"../data/target_promoter_sequences.faa\",\"r\") as ffile:\n",
    "    for line in ffile.readlines():\n",
    "        if line.startswith(\">\"):\n",
    "            target_promoters.append(line.rstrip().split(\">\")[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a9aeee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(target_promoters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65e766ff",
   "metadata": {},
   "source": [
    "# Plotting Circular Genome Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b36a733",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycirclize import Circos\n",
    "from pycirclize.parser import Genbank\n",
    "from matplotlib.patches import Patch\n",
    "from matplotlib.lines import Line2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca19da42",
   "metadata": {},
   "outputs": [],
   "source": [
    "gbk = Genbank(gbfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14106786",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_500 = pd.read_excel(\"../data/curvibacter_first_promoter_lib.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5380374e",
   "metadata": {},
   "outputs": [],
   "source": [
    "aep_to_cpl = pd.read_csv(\"../data/cpls_to_aep.csv\")\n",
    "aep_to_cpl = aep_to_cpl[[\"AEP nr\", \"strain ID\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78d81c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature in highlights:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5bb46a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "circos = Circos(sectors={gbk.name: gbk.range_size})\n",
    "circos.text(\"$\\it{Curvibacter\\ sp.}$ AEP1-3\\n\" + f\"\\n{gbk.name}\", size=9, r=20)\n",
    "sector = circos.get_sector(gbk.name)\n",
    "#circos.rect(r_lim=(60, 100), fc=\"lightgrey\", ec=\"none\", alpha=0.5)\n",
    "#sector = circos.sectors[0]\n",
    "\n",
    "major_ticks_interval = 500000\n",
    "minor_ticks_interval = 100000\n",
    "outer_track = sector.add_track((80, 85))\n",
    "outer_track.xticks_by_interval(\n",
    "    major_ticks_interval, label_formatter=lambda v: f\"{v/ 10 ** 6:.1f} Mb\"\n",
    ")\n",
    "outer_track.xticks_by_interval(minor_ticks_interval, tick_length=1, show_label=False)\n",
    "f_cds_track = sector.add_track((60, 69), r_pad_ratio=0.1)\n",
    "r_cds_track = sector.add_track((70, 79), r_pad_ratio=0.1)\n",
    "highlight_cds_track = sector.add_track((95,100), r_pad_ratio=0.1)\n",
    "\n",
    "highlights = []\n",
    "\n",
    "# extracting forward genes\n",
    "f_cds_feats = gbk.extract_features(\"CDS\", target_strand=1)\n",
    "\n",
    "f_plot_features = []\n",
    "for feature in f_cds_feats:\n",
    "    if 'old_locus_tag' in feature.qualifiers.keys(): \n",
    "        if feature.qualifiers['old_locus_tag'][0] in list(df_500.name):\n",
    "            f_plot_features.append(feature)\n",
    "        if feature.qualifiers['old_locus_tag'][0] in target_promoters:\n",
    "            highlights.append(feature)\n",
    "    else:\n",
    "        if feature.qualifiers['locus_tag'][0] in list(df_500.name):\n",
    "            f_plot_features.append(feature)\n",
    "        if feature.qualifiers['locus_tag'][0] in target_promoters:\n",
    "            highlights.append(feature)\n",
    "\n",
    "# plot forward genes\n",
    "f_cds_track.genomic_features(f_plot_features, fc=\"red\", lw=0.2, edgecolor=\"red\")\n",
    "\n",
    "\n",
    "# extracting reverse genes\n",
    "r_cds_feats = gbk.extract_features(\"CDS\", target_strand=-1)\n",
    "\n",
    "r_plot_features = []\n",
    "for feature in r_cds_feats:\n",
    "    if 'old_locus_tag' in feature.qualifiers.keys(): \n",
    "        if feature.qualifiers['old_locus_tag'][0] in list(df_500.name):\n",
    "            r_plot_features.append(feature)\n",
    "        if feature.qualifiers['old_locus_tag'][0] in target_promoters:\n",
    "            highlights.append(feature)\n",
    "    else:\n",
    "        if feature.qualifiers['locus_tag'][0] in list(df_500.name):\n",
    "            r_plot_features.append(feature)\n",
    "        if feature.qualifiers['locus_tag'][0] in target_promoters:\n",
    "            highlights.append(feature)\n",
    "\n",
    "# plot reverse genes and highlight genes\n",
    "r_cds_track.genomic_features(r_plot_features, fc=\"blue\", lw=0.2, edgecolor=\"blue\")\n",
    "highlight_cds_track.genomic_features(highlights, fc=\"orange\", lw=1, edgecolor=\"orange\")\n",
    "\n",
    "# fetch labels for highlight genes\n",
    "labels, label_pos_list = [], []\n",
    "labels_cpl, label_pos_list_cpl = [], []\n",
    "\n",
    "for index, feat in enumerate(highlights):\n",
    "    if index == 0:\n",
    "        previous_label = 0\n",
    "    else:\n",
    "        previous_label = label_pos\n",
    "    \n",
    "    start = int(str(feat.location.start))\n",
    "    end = int(str(feat.location.end))\n",
    "    label_pos = (start + end) / 2\n",
    "    \n",
    "    cpl_id = aep_to_cpl[aep_to_cpl[\"AEP nr\"] == feat.qualifiers[\"locus_tag\"][0]][\"strain ID\"].values\n",
    "    if len(cpl_id) > 0:\n",
    "        cpl_number = cpl_id[0]\n",
    "    else:\n",
    "        cpl_number = \"\"\n",
    "    \n",
    "    gene_name = feat.qualifiers.get(\"gene\", [None])[0]\n",
    "    if gene_name is not None:\n",
    "        labels.append(gene_name + \" - \" + cpl_number)\n",
    "        label_pos_list.append(label_pos)\n",
    "    else:\n",
    "        labels_cpl.append(cpl_number)\n",
    "        label_pos_list_cpl.append(label_pos)\n",
    "        \n",
    "highlight_cds_track.xticks(label_pos_list, labels, label_size=8, label_orientation=\"vertical\")\n",
    "highlight_cds_track.xticks(label_pos_list_cpl, labels_cpl, label_size=5, label_orientation=\"vertical\")\n",
    "\n",
    "## Plot xticks (interval = 10 Kb)\n",
    "#highlight_cds_track.xticks_by_interval(\n",
    "#    10000, outer=False, label_formatter=lambda v: f\"{v/1000:.1f} Kb\"\n",
    "#)\n",
    "\n",
    "# plot gc content\n",
    "gc_content_track = sector.add_track((40, 55))\n",
    "\n",
    "pos_list, gc_contents = gbk.calc_gc_content()\n",
    "gc_contents = gc_contents - gbk.calc_genome_gc_content()\n",
    "positive_gc_contents = np.where(gc_contents > 0, gc_contents, 0)\n",
    "negative_gc_contents = np.where(gc_contents < 0, gc_contents, 0)\n",
    "abs_max_gc_content = np.max(np.abs(gc_contents))\n",
    "vmin, vmax = -abs_max_gc_content, abs_max_gc_content\n",
    "gc_content_track.fill_between(\n",
    "    pos_list, positive_gc_contents, 0, vmin=vmin, vmax=vmax, color=\"black\"\n",
    ")\n",
    "gc_content_track.fill_between(\n",
    "    pos_list, negative_gc_contents, 0, vmin=vmin, vmax=vmax, color=\"grey\"\n",
    ")\n",
    "\n",
    "\n",
    "fig = circos.plotfig()\n",
    "\n",
    "# Add legend\n",
    "handles = [\n",
    "    Patch(color=\"red\", label=\"Forward 5'UTR Regions\"),\n",
    "    Patch(color=\"blue\", label=\"Reverse 5'UTR Regions\"),\n",
    "    Patch(color=\"orange\", label=\"Analyzed 5'UTR Regions\"),\n",
    "    Line2D([], [], color=\"black\", label=\"Positive GC Content\", marker=\"^\", ms=6, ls=\"None\"),\n",
    "    Line2D([], [], color=\"grey\", label=\"Negative GC Content\", marker=\"v\", ms=6, ls=\"None\")\n",
    "]\n",
    "_ = circos.ax.legend(handles=handles, bbox_to_anchor=(0.5, 0.475), loc=\"center\", fontsize=8)\n",
    "\n",
    "plt.savefig(\"../results/circos_curvibacter_genome.png\", dpi=400)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7d66ddc",
   "metadata": {},
   "source": [
    "# Trimming Length Of Sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bb3abc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the list of promoter sequences in 5' to 3' direction in a list\n",
    "raw_library = list(result_df['seq'])\n",
    "\n",
    "# determine maximum length of promoter site to be used for expression and the maximum size of oligos to order\n",
    "promoter_max_len = 98\n",
    "synthesis_maxlen = 150\n",
    "# determine sequences for cloning to be attached to the promoters\n",
    "# designed in snapgene by maurice mager\n",
    "upstream_cloningsite = \"tcgagtacgacttcggtctcaGGAGc\"\n",
    "downstream_cloningsite = \"cAATGtgagaccgaacgtcagtgatc\"\n",
    "\n",
    "# random sequence to fill synthesis order, will be cut during cloning and has no impact on construct\n",
    "# filling of random nucleotides behind cloning sites if sequence too small e.g. < 98\n",
    "fillup = \"ATCGATCGCTAGCTAGCTAGCATCGACTATCGTCGATCGATCGATGCATGCATCTGTACGATCGACTAGCTAGTCGACTATCGACTGACTGACTGACTG\"\n",
    "\n",
    "aep_seq={}\n",
    "for aep,seq in zip(result_df['aep'],result_df['seq']):\n",
    "    #save the original sequence to get raw_library.index in the end\n",
    "    rawstring = seq\n",
    "    # cut off first base to match final RBS distance in construct - why?\n",
    "    seq = seq[:-1]\n",
    "    # trimming too long promoters\n",
    "    if len(seq) > promoter_max_len:\n",
    "        print(\"[+] Trimming sequence: {} with length: {}\".format(aep,len(seq)))\n",
    "        overlength = len(seq) - promoter_max_len\n",
    "        seq = seq[overlength:]\n",
    "        \n",
    "    # adding cloning sites to both ends\n",
    "    seq = upstream_cloningsite + seq\n",
    "    seq += downstream_cloningsite\n",
    "    \n",
    "    #fill up synthesis for order of equal length oligos\n",
    "    seq = fillup + seq\n",
    "    overlength_syn = len(seq) - synthesis_maxlen\n",
    "    seq = seq[overlength_syn:]\n",
    "\n",
    "    aep_seq[aep]=seq\n",
    "\n",
    "\n",
    "# checks if size of the list, size of each oligo is correct\n",
    "for aep in aep_seq.keys():\n",
    "    if len(aep_seq[aep]) == synthesis_maxlen:\n",
    "        print(\"[+] {}\".format(aep))\n",
    "        print(\"\\t[+] length:\" + str(len(aep_seq[aep])))\n",
    "    else:\n",
    "        print(\"[-] ERROR: oligo for {} has not the correct length\".format(aep))\n",
    "if len(aep_seq.keys()) == len(raw_library):\n",
    "    print(\"[+] size of order is equal to library\")\n",
    "else:\n",
    "    print(\"[-] ERROR: size of order doesnt match original library\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f433cce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "trimmed_seqs_df=pd.DataFrame(aep_seq, index=['seq']).transpose()\n",
    "trimmed_seqs_df = trimmed_seqs_df.reset_index()\n",
    "trimmed_seqs_df.columns=['aep','trimmed_seq']\n",
    "trimmed_seqs_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fafdc61",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df=result_df.merge(trimmed_seqs_df,on='aep')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bc2ce67",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b50423c",
   "metadata": {},
   "source": [
    "## Checking Trimming Procedure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2d6440a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pContent = lambda cont:print(str(cont))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e3b9c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df[result_df['aep'] == 'AEP_00006']['seq'].apply(pContent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07308ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df[result_df['aep'] == 'AEP_00006']['trimmed_seq'].apply(pContent)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c639c5e",
   "metadata": {},
   "source": [
    "## Filtering for restriction sites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6adbbed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# restriction size filtering:\n",
    "bbs1=\"GAAGAC\"\n",
    "bsmb1=\"CGTCTC\"\n",
    "bsa1=\"GGTCTC\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9efb079",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered=[]\n",
    "for aep,seq in zip(result_df['aep'],result_df['seq']):\n",
    "    if bsa1 in str(seq):\n",
    "        filtered.append(aep)\n",
    "        print(\"[+] Found BSA1 Restriction site: {} in {}\".format(bsa1,aep))\n",
    "        idx=result_df[result_df['aep'] == aep].index.to_list()\n",
    "        if len(idx) > 1:\n",
    "            raise Exception(\"[-] Multiple rows for one target\")\n",
    "        else:\n",
    "            idx=idx[0]\n",
    "            print(\"[+] Removing row {} from dataframe\".format(idx))\n",
    "            result_df=result_df.drop(idx)#deletion of sequences with BSA1 restriction sites\n",
    "    if bbs1 in str(seq):\n",
    "        print(\"\\t[+] Found BBS1 Restriction site: {} in {}\".format(bbs1,aep))\n",
    "    if bsmb1 in str(seq):\n",
    "        print(\"\\t[+] Found BSMB1 Restriction site: {} in {}\".format(bsmb1,aep))\n",
    "print(\"[-] Number of promotors with restriction sites: {}\".format(len(filtered)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be296052",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"[+] length of final dataframe: {}\".format(len(result_df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4166ea17",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir_excel=data_dir + \"target_promotors.xlsx\"\n",
    "result_df.to_excel(data_dir_excel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa6465ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "additional_promotor_seqs=[\"AEP_03486\",\"AEP_03466\",\"AEP_03465\",\"AEP_03459\",\"AEP_02900\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
